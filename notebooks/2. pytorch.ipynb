{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import traceback\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from core.datasets import *\n",
    "from core.networks import *\n",
    "from core.models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "lr = 1e-3\n",
    "n_epochs = 34\n",
    "early_stop_threshold = 1e-2\n",
    "\n",
    "batch_size = 32\n",
    "n_workers = 4\n",
    "shuffle = True\n",
    "\n",
    "cae_latent_dim = 32\n",
    "cae_stride = 2\n",
    "resnet_model_no = 34\n",
    "\n",
    "dir_data = '/Users/Linsu Han/Documents/Data/celeba/clean/'\n",
    "dir_load = None\n",
    "dir_save = '../resources/models/'\n",
    "path_metadata = '/Users/Linsu Han/Documents/Data/celeba/list_attr_celeba.csv'\n",
    "features = ['Attractive', 'Bags_Under_Eyes', 'Bangs', 'Chubby', 'Eyeglasses', 'Male', 'Mouth_Slightly_Open', 'Mustache', 'Smiling', 'Wearing_Lipstick', 'Young']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CelebA(dir_data, path_metadata, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = int(len(dataset)*.8)\n",
    "val_len = len(dataset) - train_len\n",
    "print(train_len, val_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = torch.utils.data.Subset(dataset, list(range(0, train_len)))\n",
    "dataset_val = torch.utils.data.Subset(dataset, list(range(train_len, len(dataset))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=shuffle, num_workers=n_workers)\n",
    "dataloader_val = torch.utils.data.DataLoader(dataset_val, batch_size=batch_size, shuffle=shuffle, num_workers=n_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_shape = (3, 224, 224)\n",
    "network_cae = ConvAutoencoder(cae_latent_dim, *x_shape, stride=cae_stride).to(device)\n",
    "network_resnet = ResNet(34, len(features), in_channels=3).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cae = ModelCAE(network_cae, lr=lr)\n",
    "model_cls = ModelSigmoidClassifier(network_resnet, lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Saved Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dir_load is not None:\n",
    "    model_cae.load(dir_load + 'cae.pth')\n",
    "    model_cls.load(dir_load + 'cls.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_cae.network.train()\n",
    "model_cls.network.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "df_cae = []\n",
    "df_cls = []\n",
    "\n",
    "loss_cae_val = np.inf\n",
    "loss_cls_val = np.inf\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(f'Epoch: {epoch}')\n",
    "    \n",
    "    for idx, x, y in tqdm(dataloader_train):\n",
    "        try:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            model_cae.update(x)\n",
    "            model_cls.update(x, y)\n",
    "        except Exception as e:\n",
    "            traceback.print_exc()\n",
    "            breakpoint()\n",
    "    \n",
    "    loss_cae_train = np.mean(model_cae.loss_history['training'][-len(dataloader_train):])\n",
    "    loss_cls_train = np.mean(model_cls.loss_history['training'][-len(dataloader_train):])\n",
    "    print('Training Loss (cae):', loss_cae_train)\n",
    "    print('Training Loss (cls):', loss_cls_train)\n",
    "    \n",
    "    for idx, x, y in tqdm(dataloader_val):\n",
    "        try:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            out_cae = model_cae.eval(x)\n",
    "            out_cls = model_cls.eval(x, y)\n",
    "        except Exception as e:\n",
    "            traceback.print_exc()\n",
    "            breakpoint()\n",
    "    \n",
    "    loss_cae_val_prev = loss_cae_val\n",
    "    loss_cls_val_prev = loss_cls_val\n",
    "    \n",
    "    loss_cae_val = np.mean(model_cae.loss_history['validation'][-len(dataloader_val):])\n",
    "    loss_cls_val = np.mean(model_cls.loss_history['validation'][-len(dataloader_val):])\n",
    "    print('Validation Loss (cae):', loss_cae_val)\n",
    "    print('Validation Loss (cls):', loss_cls_val)\n",
    "\n",
    "    info_cae  = {'Epoch':epoch, 'Model':'cae', 'Training Loss':loss_cae_train, 'Validation Loss':loss_cae_val}\n",
    "    info_cls  = {'Epoch':epoch, 'Model':'cls', 'Training Loss':loss_cls_train, 'Validation Loss':loss_cls_val}\n",
    "    \n",
    "    df_cae.append(info_cae)\n",
    "    df_cls.append(info_cls)\n",
    "\n",
    "    print('-'*13)\n",
    "    \n",
    "    early_stop = loss_cls_val/loss_cls_val_prev > 1 + early_stop_threshold\n",
    "    if early_stop:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cae = pd.DataFrame(df_cae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cls = pd.DataFrame(df_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_cae['Training Loss'])\n",
    "plt.plot(df_cae['Validation Loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_cls['Training Loss'])\n",
    "plt.plot(df_cls['Validation Loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(dir_save):\n",
    "    os.makedirs(dir_save)\n",
    "model_cae.save(dir_save + 'cae.pth')\n",
    "model_cls.save(dir_save + 'cls.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
